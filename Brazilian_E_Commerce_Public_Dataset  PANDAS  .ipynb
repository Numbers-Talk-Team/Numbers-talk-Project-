{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Import data"
      ],
      "metadata": {
        "id": "qlGyiOuvlG3T"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pSBittM9gqD1"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "customers = pd.read_csv(\"olist_customers_dataset.csv\")\n",
        "orders = pd.read_csv(\"olist_orders_dataset.csv\", on_bad_lines='skip')\n",
        "order_items = pd.read_csv(\"olist_order_items_dataset.csv\")\n",
        "payments = pd.read_csv(\"olist_order_payments_dataset.csv\")\n",
        "reviews = pd.read_csv(\"olist_order_reviews_dataset.csv\")\n",
        "products = pd.read_csv(\"olist_products_dataset.csv\")\n",
        "sellers = pd.read_csv(\"olist_sellers_dataset.csv\")\n",
        "geo = pd.read_csv(\"olist_geolocation_dataset.csv\")\n",
        "categories = pd.read_csv(\"product_category_name_translation.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Show first 5 rows"
      ],
      "metadata": {
        "id": "SNV28QvDlVqf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(customers.head())\n",
        "print(orders.head())\n",
        "print(order_items.head())\n",
        "print(payments.head())\n",
        "print(reviews.head())\n",
        "print(products.head())\n",
        "print(sellers.head())\n",
        "print(geo.head())\n",
        "print(categories.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef21ef87-8295-4182-90bf-6e2cd974f3f1",
        "id": "WkNmHKSJxKpn"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                        customer_id                customer_unique_id  \\\n",
            "0  06b8999e2fba1a1fbc88172c00ba8bc7  861eff4711a542e4b93843c6dd7febb0   \n",
            "1  18955e83d337fd6b2def6b18a428ac77  290c77bc529b7ac935b93aa66c333dc3   \n",
            "2  4e7b3e00288586ebd08712fdd0374a03  060e732b5b29e8181a18229c7b0b2b5e   \n",
            "3  b2b6027bc5c5109e529d4dc6358b12c3  259dac757896d24d7702b9acbbff3f3c   \n",
            "4  4f2d8ab171c80ec8364f7c12e35b23ad  345ecd01c38d18a9036ed96c73b8d066   \n",
            "\n",
            "   customer_zip_code_prefix          customer_city customer_state  \n",
            "0                     14409                 franca             SP  \n",
            "1                      9790  sao bernardo do campo             SP  \n",
            "2                      1151              sao paulo             SP  \n",
            "3                      8775        mogi das cruzes             SP  \n",
            "4                     13056               campinas             SP  \n",
            "                           order_id                       customer_id  \\\n",
            "0  e481f51cbdc54678b7cc49136f2d6af7  9ef432eb6251297304e76186b10a928d   \n",
            "1  53cdb2fc8bc7dce0b6741e2150273451  b0830fb4747a6c6d20dea0b8c802d7ef   \n",
            "2  47770eb9100c2d0c44946d9cf07ec65d  41ce2a54c0b03bf3443c3d931a367089   \n",
            "3  949d5b44dbf5de918fe9c16f97b45f8a  f88197465ea7920adcdbec7375364d82   \n",
            "4  ad21c59c0840e6cb83a9ceb5573f8159  8ab97904e6daea8866dbdbc4fb7aad2c   \n",
            "\n",
            "  order_status order_purchase_timestamp    order_approved_at  \\\n",
            "0    delivered      2017-10-02 10:56:33  2017-10-02 11:07:15   \n",
            "1    delivered      2018-07-24 20:41:37  2018-07-26 03:24:27   \n",
            "2    delivered      2018-08-08 08:38:49  2018-08-08 08:55:23   \n",
            "3    delivered      2017-11-18 19:28:06  2017-11-18 19:45:59   \n",
            "4    delivered      2018-02-13 21:18:39  2018-02-13 22:20:29   \n",
            "\n",
            "  order_delivered_carrier_date order_delivered_customer_date  \\\n",
            "0          2017-10-04 19:55:00           2017-10-10 21:25:13   \n",
            "1          2018-07-26 14:31:00           2018-08-07 15:27:45   \n",
            "2          2018-08-08 13:50:00           2018-08-17 18:06:29   \n",
            "3          2017-11-22 13:39:59           2017-12-02 00:28:42   \n",
            "4          2018-02-14 19:46:34           2018-02-16 18:17:02   \n",
            "\n",
            "  order_estimated_delivery_date  \n",
            "0           2017-10-18 00:00:00  \n",
            "1           2018-08-13 00:00:00  \n",
            "2           2018-09-04 00:00:00  \n",
            "3           2017-12-15 00:00:00  \n",
            "4           2018-02-26 00:00:00  \n",
            "                           order_id  order_item_id  \\\n",
            "0  00010242fe8c5a6d1ba2dd792cb16214              1   \n",
            "1  00018f77f2f0320c557190d7a144bdd3              1   \n",
            "2  000229ec398224ef6ca0657da4fc703e              1   \n",
            "3  00024acbcdf0a6daa1e931b038114c75              1   \n",
            "4  00042b26cf59d7ce69dfabb4e55b4fd9              1   \n",
            "\n",
            "                         product_id                         seller_id  \\\n",
            "0  4244733e06e7ecb4970a6e2683c13e61  48436dade18ac8b2bce089ec2a041202   \n",
            "1  e5f2d52b802189ee658865ca93d83a8f  dd7ddc04e1b6c2c614352b383efe2d36   \n",
            "2  c777355d18b72b67abbeef9df44fd0fd  5b51032eddd242adc84c38acab88f23d   \n",
            "3  7634da152a4610f1595efa32f14722fc  9d7a1d34a5052409006425275ba1c2b4   \n",
            "4  ac6c3623068f30de03045865e4e10089  df560393f3a51e74553ab94004ba5c87   \n",
            "\n",
            "   shipping_limit_date   price  freight_value  \n",
            "0  2017-09-19 09:45:35   58.90          13.29  \n",
            "1  2017-05-03 11:05:13  239.90          19.93  \n",
            "2  2018-01-18 14:48:30  199.00          17.87  \n",
            "3  2018-08-15 10:10:18   12.99          12.79  \n",
            "4  2017-02-13 13:57:51  199.90          18.14  \n",
            "                           order_id  payment_sequential payment_type  \\\n",
            "0  b81ef226f3fe1789b1e8b2acac839d17                   1  credit_card   \n",
            "1  a9810da82917af2d9aefd1278f1dcfa0                   1  credit_card   \n",
            "2  25e8ea4e93396b6fa0d3dd708e76c1bd                   1  credit_card   \n",
            "3  ba78997921bbcdc1373bb41e913ab953                   1  credit_card   \n",
            "4  42fdf880ba16b47b59251dd489d4441a                   1  credit_card   \n",
            "\n",
            "   payment_installments  payment_value  \n",
            "0                     8          99.33  \n",
            "1                     1          24.39  \n",
            "2                     1          65.71  \n",
            "3                     8         107.78  \n",
            "4                     2         128.45  \n",
            "                          review_id                          order_id  \\\n",
            "0  7bc2406110b926393aa56f80a40eba40  73fc7af87114b39712e6da79b0a377eb   \n",
            "1  80e641a11e56f04c1ad469d5645fdfde  a548910a1c6147796b98fdf73dbeba33   \n",
            "2  228ce5500dc1d8e020d8d1322874b6f0  f9e4b658b201a9f2ecdecbb34bed034b   \n",
            "3  e64fb393e7b32834bb789ff8bb30750e  658677c97b385a9be170737859d3511b   \n",
            "4  f7c4243c7fe1938f181bec41a392bdeb  8e6bfb81e283fa7e4f11123a3fb894f1   \n",
            "\n",
            "   review_score review_comment_title  \\\n",
            "0             4                  NaN   \n",
            "1             5                  NaN   \n",
            "2             5                  NaN   \n",
            "3             5                  NaN   \n",
            "4             5                  NaN   \n",
            "\n",
            "                              review_comment_message review_creation_date  \\\n",
            "0                                                NaN  2018-01-18 00:00:00   \n",
            "1                                                NaN  2018-03-10 00:00:00   \n",
            "2                                                NaN  2018-02-17 00:00:00   \n",
            "3              Recebi bem antes do prazo estipulado.  2017-04-21 00:00:00   \n",
            "4  Parab√©ns lojas lannister adorei comprar pela I...  2018-03-01 00:00:00   \n",
            "\n",
            "  review_answer_timestamp  \n",
            "0     2018-01-18 21:46:59  \n",
            "1     2018-03-11 03:05:13  \n",
            "2     2018-02-18 14:36:24  \n",
            "3     2017-04-21 22:02:06  \n",
            "4     2018-03-02 10:26:53  \n",
            "                         product_id  product_category_name  \\\n",
            "0  1e9e8ef04dbcff4541ed26657ea517e5             perfumaria   \n",
            "1  3aa071139cb16b67ca9e5dea641aaa2f                  artes   \n",
            "2  96bd76ec8810374ed1b65e291975717f          esporte_lazer   \n",
            "3  cef67bcfe19066a932b7673e239eb23d                  bebes   \n",
            "4  9dc1a7de274444849c219cff195d0b71  utilidades_domesticas   \n",
            "\n",
            "   product_name_lenght  product_description_lenght  product_photos_qty  \\\n",
            "0                 40.0                       287.0                 1.0   \n",
            "1                 44.0                       276.0                 1.0   \n",
            "2                 46.0                       250.0                 1.0   \n",
            "3                 27.0                       261.0                 1.0   \n",
            "4                 37.0                       402.0                 4.0   \n",
            "\n",
            "   product_weight_g  product_length_cm  product_height_cm  product_width_cm  \n",
            "0             225.0               16.0               10.0              14.0  \n",
            "1            1000.0               30.0               18.0              20.0  \n",
            "2             154.0               18.0                9.0              15.0  \n",
            "3             371.0               26.0                4.0              26.0  \n",
            "4             625.0               20.0               17.0              13.0  \n",
            "                          seller_id  seller_zip_code_prefix  \\\n",
            "0  3442f8959a84dea7ee197c632cb2df15                   13023   \n",
            "1  d1b65fc7debc3361ea86b5f14c68d2e2                   13844   \n",
            "2  ce3ad9de960102d0677a81f5d0bb7b2d                   20031   \n",
            "3  c0f3eea2e14555b6faeea3dd58c1b1c3                    4195   \n",
            "4  51a04a8a6bdcb23deccc82b0b80742cf                   12914   \n",
            "\n",
            "         seller_city seller_state  \n",
            "0           campinas           SP  \n",
            "1         mogi guacu           SP  \n",
            "2     rio de janeiro           RJ  \n",
            "3          sao paulo           SP  \n",
            "4  braganca paulista           SP  \n",
            "   geolocation_zip_code_prefix  geolocation_lat  geolocation_lng  \\\n",
            "0                         1037       -23.545621       -46.639292   \n",
            "1                         1046       -23.546081       -46.644820   \n",
            "2                         1046       -23.546129       -46.642951   \n",
            "3                         1041       -23.544392       -46.639499   \n",
            "4                         1035       -23.541578       -46.641607   \n",
            "\n",
            "  geolocation_city geolocation_state  \n",
            "0        sao paulo                SP  \n",
            "1        sao paulo                SP  \n",
            "2        sao paulo                SP  \n",
            "3        sao paulo                SP  \n",
            "4        sao paulo                SP  \n",
            "    product_category_name product_category_name_english\n",
            "0            beleza_saude                 health_beauty\n",
            "1  informatica_acessorios         computers_accessories\n",
            "2              automotivo                          auto\n",
            "3         cama_mesa_banho                bed_bath_table\n",
            "4        moveis_decoracao               furniture_decor\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Show info"
      ],
      "metadata": {
        "id": "yTiWSMrDlvM4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "customers.info()\n",
        "orders.info()\n",
        "order_items.info()\n",
        "payments.info()\n",
        "reviews.info()\n",
        "products.info()\n",
        "sellers.info()\n",
        "geo.info()\n",
        "categories.info()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BE5cDhYPaEpU",
        "outputId": "0655062e-6ec0-4873-f404-1ff74173dbb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 99441 entries, 0 to 99440\n",
            "Data columns (total 5 columns):\n",
            " #   Column                    Non-Null Count  Dtype \n",
            "---  ------                    --------------  ----- \n",
            " 0   customer_id               99441 non-null  object\n",
            " 1   customer_unique_id        99441 non-null  object\n",
            " 2   customer_zip_code_prefix  99441 non-null  int64 \n",
            " 3   customer_city             99441 non-null  object\n",
            " 4   customer_state            99441 non-null  object\n",
            "dtypes: int64(1), object(4)\n",
            "memory usage: 3.8+ MB\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 175248 entries, 0 to 175247\n",
            "Data columns (total 8 columns):\n",
            " #   Column                         Non-Null Count   Dtype \n",
            "---  ------                         --------------   ----- \n",
            " 0   order_id                       175247 non-null  object\n",
            " 1   customer_id                    175248 non-null  object\n",
            " 2   order_status                   175248 non-null  object\n",
            " 3   order_purchase_timestamp       175247 non-null  object\n",
            " 4   order_approved_at              174967 non-null  object\n",
            " 5   order_delivered_carrier_date   172081 non-null  object\n",
            " 6   order_delivered_customer_date  170003 non-null  object\n",
            " 7   order_estimated_delivery_date  175238 non-null  object\n",
            "dtypes: object(8)\n",
            "memory usage: 10.7+ MB\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 112650 entries, 0 to 112649\n",
            "Data columns (total 7 columns):\n",
            " #   Column               Non-Null Count   Dtype  \n",
            "---  ------               --------------   -----  \n",
            " 0   order_id             112650 non-null  object \n",
            " 1   order_item_id        112650 non-null  int64  \n",
            " 2   product_id           112650 non-null  object \n",
            " 3   seller_id            112650 non-null  object \n",
            " 4   shipping_limit_date  112650 non-null  object \n",
            " 5   price                112650 non-null  float64\n",
            " 6   freight_value        112650 non-null  float64\n",
            "dtypes: float64(2), int64(1), object(4)\n",
            "memory usage: 6.0+ MB\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 103886 entries, 0 to 103885\n",
            "Data columns (total 5 columns):\n",
            " #   Column                Non-Null Count   Dtype  \n",
            "---  ------                --------------   -----  \n",
            " 0   order_id              103886 non-null  object \n",
            " 1   payment_sequential    103886 non-null  int64  \n",
            " 2   payment_type          103886 non-null  object \n",
            " 3   payment_installments  103886 non-null  int64  \n",
            " 4   payment_value         103886 non-null  float64\n",
            "dtypes: float64(1), int64(2), object(2)\n",
            "memory usage: 4.0+ MB\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 99224 entries, 0 to 99223\n",
            "Data columns (total 7 columns):\n",
            " #   Column                   Non-Null Count  Dtype \n",
            "---  ------                   --------------  ----- \n",
            " 0   review_id                99224 non-null  object\n",
            " 1   order_id                 99224 non-null  object\n",
            " 2   review_score             99224 non-null  int64 \n",
            " 3   review_comment_title     11568 non-null  object\n",
            " 4   review_comment_message   40977 non-null  object\n",
            " 5   review_creation_date     99224 non-null  object\n",
            " 6   review_answer_timestamp  99224 non-null  object\n",
            "dtypes: int64(1), object(6)\n",
            "memory usage: 5.3+ MB\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 32951 entries, 0 to 32950\n",
            "Data columns (total 9 columns):\n",
            " #   Column                      Non-Null Count  Dtype  \n",
            "---  ------                      --------------  -----  \n",
            " 0   product_id                  32951 non-null  object \n",
            " 1   product_category_name       32341 non-null  object \n",
            " 2   product_name_lenght         32341 non-null  float64\n",
            " 3   product_description_lenght  32341 non-null  float64\n",
            " 4   product_photos_qty          32341 non-null  float64\n",
            " 5   product_weight_g            32949 non-null  float64\n",
            " 6   product_length_cm           32949 non-null  float64\n",
            " 7   product_height_cm           32949 non-null  float64\n",
            " 8   product_width_cm            32949 non-null  float64\n",
            "dtypes: float64(7), object(2)\n",
            "memory usage: 2.3+ MB\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3095 entries, 0 to 3094\n",
            "Data columns (total 4 columns):\n",
            " #   Column                  Non-Null Count  Dtype \n",
            "---  ------                  --------------  ----- \n",
            " 0   seller_id               3095 non-null   object\n",
            " 1   seller_zip_code_prefix  3095 non-null   int64 \n",
            " 2   seller_city             3095 non-null   object\n",
            " 3   seller_state            3095 non-null   object\n",
            "dtypes: int64(1), object(3)\n",
            "memory usage: 96.8+ KB\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 529514 entries, 0 to 529513\n",
            "Data columns (total 5 columns):\n",
            " #   Column                       Non-Null Count   Dtype  \n",
            "---  ------                       --------------   -----  \n",
            " 0   geolocation_zip_code_prefix  529514 non-null  int64  \n",
            " 1   geolocation_lat              529514 non-null  float64\n",
            " 2   geolocation_lng              529514 non-null  float64\n",
            " 3   geolocation_city             529513 non-null  object \n",
            " 4   geolocation_state            529513 non-null  object \n",
            "dtypes: float64(2), int64(1), object(2)\n",
            "memory usage: 20.2+ MB\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 71 entries, 0 to 70\n",
            "Data columns (total 2 columns):\n",
            " #   Column                         Non-Null Count  Dtype \n",
            "---  ------                         --------------  ----- \n",
            " 0   product_category_name          71 non-null     object\n",
            " 1   product_category_name_english  71 non-null     object\n",
            "dtypes: object(2)\n",
            "memory usage: 1.2+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Show missing values"
      ],
      "metadata": {
        "id": "j7aUJWssaOJC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(customers.isna().sum())\n",
        "print(orders.isna().sum())\n",
        "print(order_items.isna().sum())\n",
        "print(payments.isna().sum())\n",
        "print(reviews.isna().sum())\n",
        "print(products.isna().sum())\n",
        "print(sellers.isna().sum())\n",
        "print(geo.isna().sum())\n",
        "print(categories.isna().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pE7civE1E7cb",
        "outputId": "f40d1f75-e911-486a-e339-2a7d11a9e2f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "customer_id                 0\n",
            "customer_unique_id          0\n",
            "customer_zip_code_prefix    0\n",
            "customer_city               0\n",
            "customer_state              0\n",
            "dtype: int64\n",
            "order_id                            1\n",
            "customer_id                         0\n",
            "order_status                        0\n",
            "order_purchase_timestamp            1\n",
            "order_approved_at                 163\n",
            "order_delivered_carrier_date     1788\n",
            "order_delivered_customer_date    2971\n",
            "order_estimated_delivery_date      10\n",
            "dtype: int64\n",
            "order_id               0\n",
            "order_item_id          0\n",
            "product_id             0\n",
            "seller_id              0\n",
            "shipping_limit_date    0\n",
            "price                  0\n",
            "freight_value          0\n",
            "dtype: int64\n",
            "order_id                0\n",
            "payment_sequential      0\n",
            "payment_type            0\n",
            "payment_installments    0\n",
            "payment_value           0\n",
            "dtype: int64\n",
            "review_id                  0\n",
            "order_id                   0\n",
            "review_score               0\n",
            "review_comment_title       0\n",
            "review_comment_message     0\n",
            "review_creation_date       0\n",
            "review_answer_timestamp    0\n",
            "dtype: int64\n",
            "product_id                    0\n",
            "product_category_name         0\n",
            "product_name_lenght           0\n",
            "product_description_lenght    0\n",
            "product_photos_qty            0\n",
            "product_weight_g              0\n",
            "product_length_cm             0\n",
            "product_height_cm             0\n",
            "product_width_cm              0\n",
            "dtype: int64\n",
            "seller_id                 0\n",
            "seller_zip_code_prefix    0\n",
            "seller_city               0\n",
            "seller_state              0\n",
            "dtype: int64\n",
            "geolocation_zip_code_prefix    0\n",
            "geolocation_lat                0\n",
            "geolocation_lng                0\n",
            "geolocation_city               1\n",
            "geolocation_state              1\n",
            "dtype: int64\n",
            "product_category_name            0\n",
            "product_category_name_english    0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Solve nulls in reviews"
      ],
      "metadata": {
        "id": "kKZ9SVeKDCaL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reviews['review_comment_title'].fillna('No title', inplace=True)\n",
        "reviews['review_comment_message'].fillna('No comment', inplace=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EVrE8nWDIEsE",
        "outputId": "2e50c33a-d372-4939-a8fa-6325829dc53b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1389943730.py:1: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  reviews['review_comment_title'].fillna('No title', inplace=True)\n",
            "/tmp/ipython-input-1389943730.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  reviews['review_comment_message'].fillna('No comment', inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Solve nulls in products"
      ],
      "metadata": {
        "id": "z9-M1P8lC6hL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "products.dropna(subset=['product_category_name', 'product_name_lenght',\n",
        "                        'product_description_lenght', 'product_photos_qty'], inplace=True)\n",
        "\n",
        "products['product_weight_g'].fillna(products['product_weight_g'].mean(), inplace=True)\n",
        "products['product_length_cm'].fillna(products['product_length_cm'].mean(), inplace=True)\n",
        "products['product_height_cm'].fillna(products['product_height_cm'].mean(), inplace=True)\n",
        "products['product_width_cm'].fillna(products['product_width_cm'].mean(), inplace=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wj4g3gCLIEdF",
        "outputId": "b04df64f-44ef-425b-c826-1448a7b41cfe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-709093077.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  products['product_weight_g'].fillna(products['product_weight_g'].mean(), inplace=True)\n",
            "/tmp/ipython-input-709093077.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  products['product_length_cm'].fillna(products['product_length_cm'].mean(), inplace=True)\n",
            "/tmp/ipython-input-709093077.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  products['product_height_cm'].fillna(products['product_height_cm'].mean(), inplace=True)\n",
            "/tmp/ipython-input-709093077.py:7: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  products['product_width_cm'].fillna(products['product_width_cm'].mean(), inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remove Duplicates"
      ],
      "metadata": {
        "id": "eWnexY0ko0yh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "customers.drop_duplicates(inplace=True)\n",
        "orders.drop_duplicates(inplace=True)\n",
        "order_items.drop_duplicates(inplace=True)\n",
        "payments.drop_duplicates(inplace=True)\n",
        "reviews.drop_duplicates(inplace=True)\n",
        "products.drop_duplicates(inplace=True)\n",
        "sellers.drop_duplicates(inplace=True)\n",
        "geo.drop_duplicates(inplace=True)\n",
        "categories.drop_duplicates(inplace=True)"
      ],
      "metadata": {
        "id": "PE6Y3Eyna6vK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Change data types of tables"
      ],
      "metadata": {
        "id": "GSr2ykOSoboD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "customers['customer_zip_code_prefix'] = customers['customer_zip_code_prefix'].astype('str')\n",
        "customers['customer_city'] = customers['customer_city'].astype('category')\n",
        "customers['customer_state'] = customers['customer_state'].astype('category')"
      ],
      "metadata": {
        "id": "rueeJ_gTofTK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "orders['order_purchase_timestamp'] = pd.to_datetime(orders['order_purchase_timestamp'], errors='coerce')\n",
        "orders['order_approved_at'] = pd.to_datetime(orders['order_approved_at'], errors='coerce')\n",
        "orders['order_delivered_carrier_date'] = pd.to_datetime(orders['order_delivered_carrier_date'], errors='coerce')\n",
        "orders['order_delivered_customer_date'] = pd.to_datetime(orders['order_delivered_customer_date'], errors='coerce')\n",
        "orders['order_estimated_delivery_date'] = pd.to_datetime(orders['order_estimated_delivery_date'], errors='coerce')"
      ],
      "metadata": {
        "id": "88Mj4nPEpVtA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "order_items['shipping_limit_date'] = pd.to_datetime(order_items['shipping_limit_date'])\n"
      ],
      "metadata": {
        "id": "X9XS03smpg_A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reviews['review_creation_date'] = pd.to_datetime(reviews['review_creation_date'])\n",
        "reviews['review_answer_timestamp'] = pd.to_datetime(reviews['review_answer_timestamp'])\n"
      ],
      "metadata": {
        "id": "FLNOZSzKpj4_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "products['product_category_name'] = products['product_category_name'].astype('category')\n",
        "products['product_name_lenght'] = products['product_name_lenght'].astype('float64')\n",
        "products['product_description_lenght'] = products['product_description_lenght'].astype('float64')\n",
        "products['product_photos_qty'] = products['product_photos_qty'].astype('float64')\n",
        "products['product_weight_g'] = products['product_weight_g'].astype('float64')\n",
        "products['product_length_cm'] = products['product_length_cm'].astype('float64')\n",
        "products['product_height_cm'] = products['product_height_cm'].astype('float64')\n",
        "products['product_width_cm'] = products['product_width_cm'].astype('float64')"
      ],
      "metadata": {
        "id": "jPhc0JFGpnEX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "payments['payment_type'] = payments['payment_type'].astype('category')\n",
        "payments['payment_installments'] = payments['payment_installments'].astype('float64')\n",
        "payments['payment_value'] = payments['payment_value'].astype('float64')"
      ],
      "metadata": {
        "id": "Ltj5sHexppaw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sellers['seller_zip_code_prefix'] = sellers['seller_zip_code_prefix'].astype('str')\n",
        "sellers['seller_city'] = sellers['seller_city'].astype('category')\n",
        "sellers['seller_state'] = sellers['seller_state'].astype('category')"
      ],
      "metadata": {
        "id": "q6_vWkJ1prvH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "geo['geolocation_zip_code_prefix'] = geo['geolocation_zip_code_prefix'].astype('str')\n",
        "geo['geolocation_city'] = geo['geolocation_city'].astype('category')\n",
        "geo['geolocation_state'] = geo['geolocation_state'].astype('category')"
      ],
      "metadata": {
        "id": "g1vhxd7_ptrH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "categories['product_category_name'] = categories['product_category_name'].astype('category')\n",
        "categories['product_category_name_english'] = categories['product_category_name_english'].astype('category')\n"
      ],
      "metadata": {
        "id": "YvALVDJwpvn_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Rename columns"
      ],
      "metadata": {
        "id": "eqiPjOfkpOhq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "customers.columns = customers.columns.str.lower().str.strip()\n",
        "orders.columns = orders.columns.str.lower().str.strip()\n",
        "order_items.columns = order_items.columns.str.lower().str.strip()\n",
        "payments.columns = payments.columns.str.lower().str.strip()\n",
        "reviews.columns = reviews.columns.str.lower().str.strip()\n",
        "products.columns = products.columns.str.lower().str.strip()\n",
        "sellers.columns = sellers.columns.str.lower().str.strip()\n",
        "geo.columns = geo.columns.str.lower().str.strip()\n",
        "categories.columns = categories.columns.str.lower().str.strip()"
      ],
      "metadata": {
        "id": "RQvB6YqibAvZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "customers = customers.applymap(lambda x: f'\"{x}\"' if not str(x).startswith('\"') else x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k5rm-OCXPUKR",
        "outputId": "4ef70fad-cc71-4224-fe5e-dbfed69ac3c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2795180330.py:1: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
            "  customers = customers.applymap(lambda x: f'\"{x}\"' if not str(x).startswith('\"') else x)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "customers['customer_city'] = customers['customer_city'].str.title()"
      ],
      "metadata": {
        "id": "em09pb7OPjWh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "customers.to_csv('olist_customers_dataset_cleaned.csv', index=False, quoting=csv.QUOTE_ALL)"
      ],
      "metadata": {
        "id": "tsgT5NrfP665"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Solve null values in orders"
      ],
      "metadata": {
        "id": "HjWRX_zYDURy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "orders = orders.dropna(subset=['order_id'])"
      ],
      "metadata": {
        "id": "Wefkf5gOr74a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "orders = orders.dropna(subset=['order_purchase_timestamp'])"
      ],
      "metadata": {
        "id": "cix_FWf1sDQC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "orders['order_approved_at'] = orders['order_approved_at'].fillna(\n",
        "    orders['order_purchase_timestamp'] + pd.Timedelta(hours=2)\n",
        ")"
      ],
      "metadata": {
        "id": "sOE65PEjsLrC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cancelled_orders = orders[orders['order_status'].isin(['canceled', 'unavailable'])]"
      ],
      "metadata": {
        "id": "piyaI9CesYCC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "orders.loc[orders['order_status'].isin(['delivered', 'shipped']),\n",
        "       'order_delivered_carrier_date'] = orders.loc[orders['order_status'].isin(['delivered', 'shipped']),\n",
        "       'order_delivered_carrier_date'].fillna(\n",
        "    orders['order_approved_at'] + pd.Timedelta(days=1)\n",
        ")"
      ],
      "metadata": {
        "id": "C5Y832qCsrO5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "conditions = [\n",
        "    orders['order_status'] == 'delivered',\n",
        "    orders['order_status'].isin(['shipped', 'invoiced']),\n",
        "    orders['order_status'].isin(['canceled', 'unavailable'])\n",
        "]\n",
        "\n",
        "choices = [\n",
        "    orders['order_estimated_delivery_date'],\n",
        "    orders['order_estimated_delivery_date'],\n",
        "    pd.NaT\n",
        "]\n",
        "\n",
        "# Calculate the values to potentially fill with using np.select\n",
        "calculated_fill_values_array = np.select(conditions, choices, default=orders['order_estimated_delivery_date'])\n",
        "\n",
        "# Convert the NumPy array to a Pandas Series, ensuring its index aligns with 'orders'\n",
        "calculated_fill_values_series = pd.Series(calculated_fill_values_array, index=orders.index)\n",
        "\n",
        "# Now use fillna with the Series\n",
        "orders['order_delivered_customer_date'] = orders['order_delivered_customer_date'].fillna(calculated_fill_values_series)"
      ],
      "metadata": {
        "id": "YU9TNwwbtJNA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge orders and customers to get customer state information\n",
        "orders_customers_merged = pd.merge(orders, customers[['customer_id', 'customer_state']], on='customer_id', how='left')\n",
        "\n",
        "# Ensure datetime types before subtraction\n",
        "orders_customers_merged['order_delivered_customer_date'] = pd.to_datetime(orders_customers_merged['order_delivered_customer_date'], errors='coerce')\n",
        "orders_customers_merged['order_purchase_timestamp'] = pd.to_datetime(orders_customers_merged['order_purchase_timestamp'], errors='coerce')\n",
        "\n",
        "# Calculate the time difference for all orders first\n",
        "orders_customers_merged['delivery_time'] = orders_customers_merged['order_delivered_customer_date'] - orders_customers_merged['order_purchase_timestamp']\n",
        "\n",
        "# Calculate average delivery time by state from the pre-calculated differences\n",
        "# .mean() on Timedelta series correctly handles NaT values\n",
        "state_avg_delivery = orders_customers_merged.groupby('customer_state', observed=False)['delivery_time'].mean()\n",
        "\n",
        "def fill_estimated_delivery(row):\n",
        "    if pd.isna(row['order_estimated_delivery_date']):\n",
        "        state = row['customer_state']\n",
        "        # Handle cases where a state might not be in state_avg_delivery (e.g., if no orders for that state)\n",
        "        # Use a default timedelta if state not found\n",
        "        avg_days = state_avg_delivery.get(state, pd.Timedelta(days=15)) # Default to 15 days if state not found\n",
        "        return row['order_purchase_timestamp'] + avg_days\n",
        "    return row['order_estimated_delivery_date']\n",
        "\n",
        "# Apply the function to the merged dataframe\n",
        "orders_customers_merged['order_estimated_delivery_date'] = orders_customers_merged.apply(fill_estimated_delivery, axis=1)\n",
        "\n",
        "# Update the original 'orders' DataFrame with the new 'order_estimated_delivery_date' values\n",
        "# Ensure alignment by 'order_id'\n",
        "orders = orders.set_index('order_id')\n",
        "orders_customers_merged = orders_customers_merged.set_index('order_id')\n",
        "orders['order_estimated_delivery_date'] = orders_customers_merged['order_estimated_delivery_date']\n",
        "orders = orders.reset_index()"
      ],
      "metadata": {
        "id": "_U3iNMqJtKC4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Solve geolocation nulls"
      ],
      "metadata": {
        "id": "rQtm_jrYD9OB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def handle_geolocation_nulls(df):\n",
        "    df_clean = df.copy()\n",
        "\n",
        "    # Fill missing geolocation_city\n",
        "    if df_clean['geolocation_city'].isnull().sum() > 0:\n",
        "        city_by_zip = df_clean.groupby('geolocation_zip_code_prefix')['geolocation_city'].agg(lambda x: x.mode().iloc[0] if not x.mode().empty else 'Unknown')\n",
        "        df_clean['geolocation_city'] = df_clean.apply(\n",
        "            lambda row: city_by_zip.get(row['geolocation_zip_code_prefix'], 'Unknown')\n",
        "            if pd.isna(row['geolocation_city']) else row['geolocation_city'],\n",
        "            axis=1\n",
        "        )\n",
        "\n",
        "    # Fill missing geolocation_state\n",
        "    if df_clean['geolocation_state'].isnull().sum() > 0:\n",
        "        state_by_zip = df_clean.groupby('geolocation_zip_code_prefix')['geolocation_state'].agg(lambda x: x.mode().iloc[0] if not x.mode().empty else 'Unknown')\n",
        "        df_clean['geolocation_state'] = df_clean.apply(\n",
        "            lambda row: state_by_zip.get(row['geolocation_zip_code_prefix'], 'Unknown')\n",
        "            if pd.isna(row['geolocation_state']) else row['geolocation_state'],\n",
        "            axis=1\n",
        "        )\n",
        "    return df_clean\n",
        "\n",
        "geo = handle_geolocation_nulls(geo)"
      ],
      "metadata": {
        "id": "y9MMIIgC8I6J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Solve orders shipping date nulls"
      ],
      "metadata": {
        "id": "awFVP4ZBEGr4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import timedelta\n",
        "import numpy as np\n",
        "\n",
        "def handle_orders_nulls_comprehensive(df):\n",
        "    \"\"\"\n",
        "    ŸÖÿπÿßŸÑÿ¨ÿ© ÿ¥ÿßŸÖŸÑÿ© ŸÑŸÑŸÇŸäŸÖ ÿßŸÑŸÖŸÅŸÇŸàÿØÿ© ŸÅŸä ÿ®ŸäÿßŸÜÿßÿ™ ÿßŸÑÿ∑ŸÑÿ®ÿßÿ™\n",
        "    \"\"\"\n",
        "    df_clean = df.copy()\n",
        "\n",
        "    print(\"üìä ÿ™ÿ≠ŸÑŸäŸÑ ÿ≠ÿßŸÑÿ© ÿßŸÑÿ∑ŸÑÿ®ÿßÿ™ ŸÇÿ®ŸÑ ÿßŸÑŸÖÿπÿßŸÑÿ¨ÿ©:\")\n",
        "    status_counts = df_clean['order_status'].value_counts()\n",
        "    print(status_counts)\n",
        "\n",
        "    # 1. ÿ≠ÿ≥ÿßÿ® ŸÖÿ™Ÿàÿ≥ÿ∑ ÿ£ŸàŸÇÿßÿ™ ÿßŸÑÿ™ÿ≥ŸÑŸäŸÖ ŸÑŸÑÿ∑ŸÑÿ®ÿßÿ™ ÿßŸÑŸÖŸÉÿ™ŸÖŸÑÿ©\n",
        "    completed_orders = df_clean[df_clean['order_status'] == 'delivered'].copy()\n",
        "\n",
        "    # Ensure datetime types for calculations within completed_orders\n",
        "    completed_orders['order_delivered_carrier_date'] = pd.to_datetime(completed_orders['order_delivered_carrier_date'], errors='coerce')\n",
        "    completed_orders['order_approved_at'] = pd.to_datetime(completed_orders['order_approved_at'], errors='coerce')\n",
        "    completed_orders['order_delivered_customer_date'] = pd.to_datetime(completed_orders['order_delivered_customer_date'], errors='coerce')\n",
        "\n",
        "    # ŸÖÿ™Ÿàÿ≥ÿ∑ ÿßŸÑŸàŸÇÿ™ ÿ®ŸäŸÜ ÿßŸÑŸÖŸàÿßŸÅŸÇÿ© Ÿàÿ™ÿ≥ŸÑŸäŸÖ ÿßŸÑŸÜÿßŸÇŸÑ\n",
        "    if not completed_orders.empty:\n",
        "        avg_carrier_delay = (completed_orders['order_delivered_carrier_date'] - completed_orders['order_approved_at']).mean()\n",
        "        avg_customer_delay = (completed_orders['order_delivered_customer_date'] - completed_orders['order_delivered_carrier_date']).mean()\n",
        "    else:\n",
        "        avg_carrier_delay = timedelta(days=2)\n",
        "        avg_customer_delay = timedelta(days=10)\n",
        "\n",
        "    print(f\"‚è±Ô∏è  ŸÖÿ™Ÿàÿ≥ÿ∑ ŸàŸÇÿ™ ÿ™ÿ≥ŸÑŸäŸÖ ÿßŸÑŸÜÿßŸÇŸÑ: {avg_carrier_delay}\")\n",
        "    print(f\"‚è±Ô∏è  ŸÖÿ™Ÿàÿ≥ÿ∑ ŸàŸÇÿ™ ÿ™ÿ≥ŸÑŸäŸÖ ÿßŸÑÿπŸÖŸäŸÑ: {avg_customer_delay}\")\n",
        "\n",
        "    # 2. ŸÖÿπÿßŸÑÿ¨ÿ© order_delivered_carrier_date (1784 ŸÖŸÅŸÇŸàÿØ)\n",
        "    carrier_conditions = [\n",
        "        df_clean['order_status'] == 'delivered',\n",
        "        df_clean['order_status'] == 'shipped',\n",
        "        df_clean['order_status'].isin(['processing', 'approved', 'invoiced']),\n",
        "        df_clean['order_status'].isin(['canceled', 'unavailable', 'created'])\n",
        "    ]\n",
        "\n",
        "    carrier_choices = [\n",
        "        df_clean['order_approved_at'] + avg_carrier_delay,  # ÿ™ŸÖ ÿßŸÑÿ™ÿ≥ŸÑŸäŸÖ\n",
        "        df_clean['order_approved_at'] + avg_carrier_delay,  # ÿ™ŸÖ ÿßŸÑÿ¥ÿ≠ŸÜ\n",
        "        df_clean['order_approved_at'] + timedelta(days=3),  # ŸÇŸäÿØ ÿßŸÑŸÖÿπÿßŸÑÿ¨ÿ©\n",
        "        pd.NaT  # ŸÖŸÑÿ∫ÿßÿ© ÿ£Ÿà ÿ∫Ÿäÿ± ŸÖÿ™ÿßÿ≠ÿ©\n",
        "    ]\n",
        "\n",
        "    # Ensure order_approved_at is datetime type before adding timedelta\n",
        "    df_clean['order_approved_at'] = pd.to_datetime(df_clean['order_approved_at'], errors='coerce')\n",
        "    df_clean['order_delivered_carrier_date'] = np.select(\n",
        "        carrier_conditions,\n",
        "        carrier_choices,\n",
        "        default=df_clean['order_approved_at'] + avg_carrier_delay\n",
        "    )\n",
        "\n",
        "    # 3. ŸÖÿπÿßŸÑÿ¨ÿ© order_delivered_customer_date (1233 ŸÖŸÅŸÇŸàÿØ)\n",
        "    customer_conditions = [\n",
        "        df_clean['order_status'] == 'delivered',\n",
        "        df_clean['order_status'].isin(['shipped', 'invoiced']),\n",
        "        df_clean['order_status'].isin(['canceled', 'unavailable'])\n",
        "    ]\n",
        "\n",
        "    customer_choices = [\n",
        "        # ŸÑŸÑÿ∑ŸÑÿ®ÿßÿ™ ÿßŸÑŸÖÿ≥ŸÑŸÖÿ©: ŸÜÿ≥ÿ™ÿÆÿØŸÖ ÿßŸÑÿ™ÿßÿ±ŸäÿÆ ÿßŸÑŸÅÿπŸÑŸä ÿ£Ÿà ÿßŸÑŸÖÿ™ŸàŸÇÿπ\n",
        "        df_clean['order_estimated_delivery_date'],\n",
        "        # ŸÑŸÑÿ∑ŸÑÿ®ÿßÿ™ ŸÇŸäÿØ ÿßŸÑÿ¥ÿ≠ŸÜ: ŸÜÿ≥ÿ™ÿÆÿØŸÖ ÿßŸÑÿ™ÿßÿ±ŸäÿÆ ÿßŸÑŸÖÿ™ŸàŸÇÿπ\n",
        "        df_clean['order_estimated_delivery_date'],\n",
        "        # ŸÑŸÑÿ∑ŸÑÿ®ÿßÿ™ ÿßŸÑŸÖŸÑÿ∫ÿßÿ©: ŸÜÿ™ÿ±ŸÉŸáÿß ŸÅÿßÿ±ÿ∫ÿ©\n",
        "        pd.NaT\n",
        "    ]\n",
        "\n",
        "    # Ensure order_estimated_delivery_date is datetime type\n",
        "    df_clean['order_estimated_delivery_date'] = pd.to_datetime(df_clean['order_estimated_delivery_date'], errors='coerce')\n",
        "    df_clean['order_delivered_customer_date'] = np.select(\n",
        "        customer_conditions,\n",
        "        customer_choices,\n",
        "        default=df_clean['order_estimated_delivery_date']\n",
        "    )\n",
        "\n",
        "    # 4. ÿ™ÿ≠ÿ≥ŸäŸÜ ÿßŸÑÿØŸÇÿ© ÿ®ÿßÿ≥ÿ™ÿÆÿØÿßŸÖ ÿßŸÑÿ®ŸäÿßŸÜÿßÿ™ ÿßŸÑÿ≠ÿßŸÑŸäÿ©\n",
        "    # ŸÑŸÑÿ∑ŸÑÿ®ÿßÿ™ ÿßŸÑÿ™Ÿä ŸÑÿØŸäŸáÿß ÿ™ÿßÿ±ŸäÿÆ ÿ™ÿ≥ŸÑŸäŸÖ ŸÑŸÑŸÜÿßŸÇŸÑ ŸàŸÑŸÉŸÜ ŸÑŸäÿ≥ ŸÑŸÑÿπŸÖŸäŸÑ\n",
        "    mask = (df_clean['order_delivered_carrier_date'].notna() &\n",
        "            df_clean['order_delivered_customer_date'].isna() &\n",
        "            df_clean['order_status'].isin(['delivered', 'shipped']))\n",
        "\n",
        "    df_clean.loc[mask, 'order_delivered_customer_date'] = (\n",
        "        df_clean.loc[mask, 'order_delivered_carrier_date'] + avg_customer_delay\n",
        "    )\n",
        "\n",
        "    return df_clean\n",
        "\n",
        "# ÿ™ÿ∑ÿ®ŸäŸÇ ÿßŸÑÿ≠ŸÑ\n",
        "orders = handle_orders_nulls_comprehensive(orders)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sVMVFoMA9ezW",
        "outputId": "bd65e7be-81da-4bf1-85bc-c4e2d5dce8ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìä ÿ™ÿ≠ŸÑŸäŸÑ ÿ≠ÿßŸÑÿ© ÿßŸÑÿ∑ŸÑÿ®ÿßÿ™ ŸÇÿ®ŸÑ ÿßŸÑŸÖÿπÿßŸÑÿ¨ÿ©:\n",
            "order_status\n",
            "delivered              96472\n",
            "shipped                 1107\n",
            "canceled                 625\n",
            "unavailable              609\n",
            "invoiced                 314\n",
            "processing               301\n",
            "created                    5\n",
            "approved                   2\n",
            "2018-07-25 09:36:25        1\n",
            "2018-03-16 21:10:51        1\n",
            "2017-09-25 21:22:09        1\n",
            "2017-08-01 09:48:08        1\n",
            "2018-02-11 19:36:30        1\n",
            "2017-07-10 15:12:27        1\n",
            "Name: count, dtype: int64\n",
            "‚è±Ô∏è  ŸÖÿ™Ÿàÿ≥ÿ∑ ŸàŸÇÿ™ ÿ™ÿ≥ŸÑŸäŸÖ ÿßŸÑŸÜÿßŸÇŸÑ: 1 days 00:00:00\n",
            "‚è±Ô∏è  ŸÖÿ™Ÿàÿ≥ÿ∑ ŸàŸÇÿ™ ÿ™ÿ≥ŸÑŸäŸÖ ÿßŸÑÿπŸÖŸäŸÑ: 11 days 03:13:30.485623026\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def final_solution_keep_nulls(df):\n",
        "    \"\"\"\n",
        "    ÿßŸÑÿÆŸäÿßÿ± ÿßŸÑÿ£ŸÖÿ´ŸÑ: ÿßŸÑÿßÿ≠ÿ™ŸÅÿßÿ∏ ÿ®ÿßŸÑŸÇŸäŸÖ ÿßŸÑŸÖŸÅŸÇŸàÿØÿ© ŸÑŸÑÿ∑ŸÑÿ®ÿßÿ™ ÿßŸÑŸÖŸÑÿ∫ÿßÿ©\n",
        "    \"\"\"\n",
        "    df_final = df.copy()\n",
        "\n",
        "    # ŸÅŸÇÿ∑ ŸÜŸÖŸÑÿ£ ÿßŸÑÿ∑ŸÑÿ®ÿßÿ™ ÿßŸÑÿ™Ÿä ŸÖŸÜ ÿßŸÑŸÖŸÜÿ∑ŸÇŸä ÿ£ŸÜ ÿ™ŸÉŸàŸÜ ŸÖÿ≥ŸÑŸÖÿ©\n",
        "    deliverable_mask = df_final['order_status'].isin(['delivered', 'shipped', 'invoiced'])\n",
        "\n",
        "    # ŸÜÿ≥ÿ™ÿÆÿØŸÖ ÿßŸÑÿ™ÿßÿ±ŸäÿÆ ÿßŸÑŸÖÿ™ŸàŸÇÿπ ŸÑŸÑÿ∑ŸÑÿ®ÿßÿ™ ÿßŸÑŸÖÿ≥ŸÑŸÖÿ© ÿßŸÑÿ™Ÿä ŸÑÿß ÿ™Ÿàÿ¨ÿØ ŸÑŸáÿß ÿ®ŸäÿßŸÜÿßÿ™\n",
        "    df_final.loc[deliverable_mask & df_final['order_delivered_customer_date'].isna(),\n",
        "                'order_delivered_customer_date'] = df_final['order_estimated_delivery_date']\n",
        "\n",
        "    # ÿßŸÑÿ®ÿßŸÇŸä ŸÜÿ™ÿ±ŸÉŸá ŸÉŸÖÿß ŸáŸà - ŸäŸÖÿ´ŸÑ ÿ∑ŸÑÿ®ÿßÿ™ ŸÖŸÑÿ∫ÿßÿ© ÿ≠ŸÇŸäŸÇŸäÿ©\n",
        "    return df_final\n",
        "\n",
        "df_optimal = final_solution_keep_nulls(orders)"
      ],
      "metadata": {
        "id": "sE68iTC-COeN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Review after cleaning"
      ],
      "metadata": {
        "id": "8qIQlYjLDfri"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(customers.isna().sum())\n",
        "print(orders.isna().sum())\n",
        "print(order_items.isna().sum())\n",
        "print(payments.isna().sum())\n",
        "print(reviews.isna().sum())\n",
        "print(products.isna().sum())\n",
        "print(sellers.isna().sum())\n",
        "print(geo.isna().sum())\n",
        "print(categories.isna().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i1bOAU1XDgaC",
        "outputId": "3eb5ab43-e643-40f1-d26a-2570c58e9ca3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "customer_id                 0\n",
            "customer_unique_id          0\n",
            "customer_zip_code_prefix    0\n",
            "customer_city               0\n",
            "customer_state              0\n",
            "dtype: int64\n",
            "order_id                            0\n",
            "customer_id                         0\n",
            "order_status                        0\n",
            "order_purchase_timestamp            0\n",
            "order_approved_at                   0\n",
            "order_delivered_carrier_date     1239\n",
            "order_delivered_customer_date    1234\n",
            "order_estimated_delivery_date       0\n",
            "dtype: int64\n",
            "order_id               0\n",
            "order_item_id          0\n",
            "product_id             0\n",
            "seller_id              0\n",
            "shipping_limit_date    0\n",
            "price                  0\n",
            "freight_value          0\n",
            "dtype: int64\n",
            "order_id                0\n",
            "payment_sequential      0\n",
            "payment_type            0\n",
            "payment_installments    0\n",
            "payment_value           0\n",
            "dtype: int64\n",
            "review_id                  0\n",
            "order_id                   0\n",
            "review_score               0\n",
            "review_comment_title       0\n",
            "review_comment_message     0\n",
            "review_creation_date       0\n",
            "review_answer_timestamp    0\n",
            "dtype: int64\n",
            "product_id                    0\n",
            "product_category_name         0\n",
            "product_name_lenght           0\n",
            "product_description_lenght    0\n",
            "product_photos_qty            0\n",
            "product_weight_g              0\n",
            "product_length_cm             0\n",
            "product_height_cm             0\n",
            "product_width_cm              0\n",
            "dtype: int64\n",
            "seller_id                 0\n",
            "seller_zip_code_prefix    0\n",
            "seller_city               0\n",
            "seller_state              0\n",
            "dtype: int64\n",
            "geolocation_zip_code_prefix    0\n",
            "geolocation_lat                0\n",
            "geolocation_lng                0\n",
            "geolocation_city               0\n",
            "geolocation_state              0\n",
            "dtype: int64\n",
            "product_category_name            0\n",
            "product_category_name_english    0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "customers.info()\n",
        "orders.info()\n",
        "order_items.info()\n",
        "payments.info()\n",
        "reviews.info()\n",
        "products.info()\n",
        "sellers.info()\n",
        "geo.info()\n",
        "categories.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LKi8CwkVDqcx",
        "outputId": "b25ea002-8eb0-406a-dc00-c3f0321f0202"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 99441 entries, 0 to 99440\n",
            "Data columns (total 5 columns):\n",
            " #   Column                    Non-Null Count  Dtype   \n",
            "---  ------                    --------------  -----   \n",
            " 0   customer_id               99441 non-null  object  \n",
            " 1   customer_unique_id        99441 non-null  object  \n",
            " 2   customer_zip_code_prefix  99441 non-null  object  \n",
            " 3   customer_city             99441 non-null  category\n",
            " 4   customer_state            99441 non-null  category\n",
            "dtypes: category(2), object(3)\n",
            "memory usage: 2.7+ MB\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 99441 entries, 0 to 99440\n",
            "Data columns (total 8 columns):\n",
            " #   Column                         Non-Null Count  Dtype         \n",
            "---  ------                         --------------  -----         \n",
            " 0   order_id                       99441 non-null  object        \n",
            " 1   customer_id                    99441 non-null  object        \n",
            " 2   order_status                   99441 non-null  object        \n",
            " 3   order_purchase_timestamp       99441 non-null  datetime64[ns]\n",
            " 4   order_approved_at              99441 non-null  datetime64[ns]\n",
            " 5   order_delivered_carrier_date   98202 non-null  object        \n",
            " 6   order_delivered_customer_date  98207 non-null  object        \n",
            " 7   order_estimated_delivery_date  99441 non-null  datetime64[ns]\n",
            "dtypes: datetime64[ns](3), object(5)\n",
            "memory usage: 6.1+ MB\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 112650 entries, 0 to 112649\n",
            "Data columns (total 7 columns):\n",
            " #   Column               Non-Null Count   Dtype         \n",
            "---  ------               --------------   -----         \n",
            " 0   order_id             112650 non-null  object        \n",
            " 1   order_item_id        112650 non-null  int64         \n",
            " 2   product_id           112650 non-null  object        \n",
            " 3   seller_id            112650 non-null  object        \n",
            " 4   shipping_limit_date  112650 non-null  datetime64[ns]\n",
            " 5   price                112650 non-null  float64       \n",
            " 6   freight_value        112650 non-null  float64       \n",
            "dtypes: datetime64[ns](1), float64(2), int64(1), object(3)\n",
            "memory usage: 6.0+ MB\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 103886 entries, 0 to 103885\n",
            "Data columns (total 5 columns):\n",
            " #   Column                Non-Null Count   Dtype   \n",
            "---  ------                --------------   -----   \n",
            " 0   order_id              103886 non-null  object  \n",
            " 1   payment_sequential    103886 non-null  int64   \n",
            " 2   payment_type          103886 non-null  category\n",
            " 3   payment_installments  103886 non-null  float64 \n",
            " 4   payment_value         103886 non-null  float64 \n",
            "dtypes: category(1), float64(2), int64(1), object(1)\n",
            "memory usage: 3.3+ MB\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 99224 entries, 0 to 99223\n",
            "Data columns (total 7 columns):\n",
            " #   Column                   Non-Null Count  Dtype         \n",
            "---  ------                   --------------  -----         \n",
            " 0   review_id                99224 non-null  object        \n",
            " 1   order_id                 99224 non-null  object        \n",
            " 2   review_score             99224 non-null  int64         \n",
            " 3   review_comment_title     99224 non-null  object        \n",
            " 4   review_comment_message   99224 non-null  object        \n",
            " 5   review_creation_date     99224 non-null  datetime64[ns]\n",
            " 6   review_answer_timestamp  99224 non-null  datetime64[ns]\n",
            "dtypes: datetime64[ns](2), int64(1), object(4)\n",
            "memory usage: 5.3+ MB\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 32341 entries, 0 to 32950\n",
            "Data columns (total 9 columns):\n",
            " #   Column                      Non-Null Count  Dtype   \n",
            "---  ------                      --------------  -----   \n",
            " 0   product_id                  32341 non-null  object  \n",
            " 1   product_category_name       32341 non-null  category\n",
            " 2   product_name_lenght         32341 non-null  float64 \n",
            " 3   product_description_lenght  32341 non-null  float64 \n",
            " 4   product_photos_qty          32341 non-null  float64 \n",
            " 5   product_weight_g            32341 non-null  float64 \n",
            " 6   product_length_cm           32341 non-null  float64 \n",
            " 7   product_height_cm           32341 non-null  float64 \n",
            " 8   product_width_cm            32341 non-null  float64 \n",
            "dtypes: category(1), float64(7), object(1)\n",
            "memory usage: 2.3+ MB\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3095 entries, 0 to 3094\n",
            "Data columns (total 4 columns):\n",
            " #   Column                  Non-Null Count  Dtype   \n",
            "---  ------                  --------------  -----   \n",
            " 0   seller_id               3095 non-null   object  \n",
            " 1   seller_zip_code_prefix  3095 non-null   object  \n",
            " 2   seller_city             3095 non-null   category\n",
            " 3   seller_state            3095 non-null   category\n",
            "dtypes: category(2), object(2)\n",
            "memory usage: 79.2+ KB\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 367527 entries, 0 to 529513\n",
            "Data columns (total 5 columns):\n",
            " #   Column                       Non-Null Count   Dtype  \n",
            "---  ------                       --------------   -----  \n",
            " 0   geolocation_zip_code_prefix  367527 non-null  object \n",
            " 1   geolocation_lat              367527 non-null  float64\n",
            " 2   geolocation_lng              367527 non-null  float64\n",
            " 3   geolocation_city             367527 non-null  object \n",
            " 4   geolocation_state            367527 non-null  object \n",
            "dtypes: float64(2), object(3)\n",
            "memory usage: 16.8+ MB\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 71 entries, 0 to 70\n",
            "Data columns (total 2 columns):\n",
            " #   Column                         Non-Null Count  Dtype   \n",
            "---  ------                         --------------  -----   \n",
            " 0   product_category_name          71 non-null     category\n",
            " 1   product_category_name_english  71 non-null     category\n",
            "dtypes: category(2)\n",
            "memory usage: 5.5 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "# ÿØÿßŸÑÿ© ŸÑÿ™ŸÜÿ∏ŸäŸÅ Ÿàÿ™Ÿàÿ≠ŸäÿØ ÿ£ÿ≥ŸÖÿßÿ° ÿßŸÑŸÖÿØŸÜ\n",
        "def clean_city_name(city):\n",
        "    if pd.isna(city):\n",
        "        return city\n",
        "\n",
        "    city = str(city).strip().lower()\n",
        "\n",
        "    # ÿ•ÿ≤ÿßŸÑÿ© ÿ£Ÿä ÿ•ÿ∂ÿßŸÅÿßÿ™ ÿ∫Ÿäÿ± ŸÖÿ±ÿ∫Ÿàÿ®ÿ©\n",
        "    city = re.sub(r'[^\\w\\s]', '', city)\n",
        "\n",
        "    # ÿ™ÿµÿ≠Ÿäÿ≠ ÿßŸÑÿ£ÿÆÿ∑ÿßÿ° ÿßŸÑÿ¥ÿßÿ¶ÿπÿ© ŸÅŸä ÿ£ÿ≥ŸÖÿßÿ° ÿßŸÑŸÖÿØŸÜ ÿßŸÑÿ®ÿ±ÿßÿ≤ŸäŸÑŸäÿ©\n",
        "    corrections = {\n",
        "        'sao paulo': 's√£o paulo',\n",
        "        'sao bernardo do campo': 's√£o bernardo do campo',\n",
        "        'sao jose dos campos': 's√£o jos√© dos campos',\n",
        "        'sao jose': 's√£o jos√©',\n",
        "        'sao goncalo': 's√£o gon√ßalo',\n",
        "        'sao luis': 's√£o lu√≠s',\n",
        "        'sao vicente': 's√£o vicente',\n",
        "        'sao carlos': 's√£o carlos',\n",
        "        'sao jose do rio preto': 's√£o jos√© do rio preto',\n",
        "        'sao bento do sul': 's√£o bento do sul',\n",
        "        'sao sepe': 's√£o sep√©',\n",
        "        'sao sebastiao do paraiso': 's√£o sebasti√£o do para√≠so',\n",
        "        'sao miguel do oeste': 's√£o miguel do oeste',\n",
        "        'sao pedro da aldeia': 's√£o pedro da aldeia',\n",
        "        'sao joao de meriti': 's√£o jo√£o de meriti',\n",
        "        'sao joao da boa vista': 's√£o jo√£o da boa vista',\n",
        "        'sao jose da coroa grande': 's√£o jos√© da coroa grande',\n",
        "        'sao bento do sapucai': 's√£o bento do sapuca√≠',\n",
        "        'sao goncalo do rio abaixo': 's√£o gon√ßalo do rio abaixo',\n",
        "        'sao jorge do ivai': 's√£o jorge do iva√≠',\n",
        "        'sao jose dos pinhais': 's√£o jos√© dos pinhais',\n",
        "        'goiania': 'goi√¢nia',\n",
        "        'belem': 'bel√©m',\n",
        "        'jaboatao dos guararapes': 'jaboat√£o dos guararapes',\n",
        "        'maceio': 'macei√≥',\n",
        "        'manaus': 'manaus',\n",
        "        'campinas': 'campinas',\n",
        "        'fortaleza': 'fortaleza',\n",
        "        'recife': 'recife',\n",
        "        'curitiba': 'curitiba',\n",
        "        'belo horizonte': 'belo horizonte',\n",
        "        'porto alegre': 'porto alegre',\n",
        "        'rio de janeiro': 'rio de janeiro',\n",
        "        'salvador': 'salvador',\n",
        "        'brasilia': 'bras√≠lia',\n",
        "        'florianopolis': 'florian√≥polis',\n",
        "        'vitoria': 'vit√≥ria',\n",
        "        'santos': 'santos',\n",
        "        'guarulhos': 'guarulhos',\n",
        "        'niteroi': 'niter√≥i',\n",
        "        'cuiaba': 'cuiab√°',\n",
        "        'joao pessoa': 'jo√£o pessoa',\n",
        "        'teresina': 'teresina',\n",
        "        'aracaju': 'aracaju',\n",
        "        'campo grande': 'campo grande',\n",
        "        'macapa': 'macap√°',\n",
        "        'palmas': 'palmas',\n",
        "        'juiz de fora': 'juiz de fora',\n",
        "        'volta redonda': 'volta redonda',\n",
        "        'feira de santana': 'feira de santana',\n",
        "        'santa maria': 'santa maria',\n",
        "        'novo hamburgo': 'novo hamburgo',\n",
        "        'caxias do sul': 'caxias do sul',\n",
        "        'ribeirao preto': 'ribeir√£o preto',\n",
        "        'uberlandia': 'uberl√¢ndia',\n",
        "        'sorocaba': 'sorocaba',\n",
        "        'contagem': 'contagem',\n",
        "        'aracatuba': 'ara√ßatuba',\n",
        "        'piracicaba': 'piracicaba',\n",
        "        'americana': 'americana',\n",
        "        'marilia': 'mar√≠lia',\n",
        "        'presidente prudente': 'presidente prudente',\n",
        "        'divinopolis': 'divin√≥polis',\n",
        "        'sao jose do rio preto': 's√£o jos√© do rio preto',\n",
        "        'itatiaia': 'itatiaia',\n",
        "        'mogi das cruzes': 'mogi das cruzes',\n",
        "        'jundiai': 'jundia√≠',\n",
        "        'botucatu': 'botucatu',\n",
        "        'praia grande': 'praia grande',\n",
        "        'cascavel': 'cascavel',\n",
        "        'petropolis': 'petr√≥polis',\n",
        "        'uberaba': 'uberaba',\n",
        "        'varzea grande': 'v√°rzea grande',\n",
        "        'taubate': 'taubat√©',\n",
        "        'pindamonhangaba': 'pindamonhangaba',\n",
        "        'itapevi': 'itapevi',\n",
        "        'barueri': 'barueri',\n",
        "        'guaruja': 'guaruj√°',\n",
        "        'embu das artes': 'embu das artes',\n",
        "        'cotia': 'cotia',\n",
        "        'itaborai': 'itabora√≠',\n",
        "        'sao caetano do sul': 's√£o caetano do sul',\n",
        "        'votorantim': 'votorantim',\n",
        "        'birigui': 'birigui',\n",
        "        'valinhos': 'valinhos',\n",
        "        'vinhedo': 'vinhedo',\n",
        "        'louveira': 'louveira',\n",
        "        'jaragua do sul': 'jaragu√° do sul',\n",
        "        'joinville': 'joinville',\n",
        "        'blumenau': 'blumenau',\n",
        "        'florianopolis': 'florian√≥polis',\n",
        "        'chapeco': 'chapec√≥',\n",
        "        'criciuma': 'crici√∫ma',\n",
        "        'lages': 'lages',\n",
        "        'tubarao': 'tubar√£o',\n",
        "        'ituiutaba': 'ituiutaba',\n",
        "        'uberlandia': 'uberl√¢ndia',\n",
        "        'divinopolis': 'divin√≥polis',\n",
        "        'sete lagoas': 'sete lagoas',\n",
        "        'ipatinga': 'ipatinga',\n",
        "        'timoteo': 'tim√≥teo',\n",
        "        'coronel fabriciano': 'coronel fabriciano',\n",
        "        'juiz de fora': 'juiz de fora',\n",
        "        'barbacena': 'barbacena',\n",
        "        'varginha': 'varginha',\n",
        "        'pouso alegre': 'pouso alegre',\n",
        "        'passos': 'passos',\n",
        "        'araxa': 'arax√°',\n",
        "        'patos de minas': 'patos de minas',\n",
        "        'nova lima': 'nova lima',\n",
        "        'santa luzia': 'santa luzia',\n",
        "        'venda nova': 'venda nova',\n",
        "        'betim': 'betim',\n",
        "        'contagem': 'contagem',\n",
        "        'ribeirao das neves': 'ribeir√£o das neves',\n",
        "        'sabara': 'sabar√°',\n",
        "        'ibirit√©': 'ibirit√©',\n",
        "        'itatiaia': 'itatiaia',\n",
        "        'resende': 'resende',\n",
        "        'volta redonda': 'volta redonda',\n",
        "        'barra mansa': 'barra mansa',\n",
        "        'petropolis': 'petr√≥polis',\n",
        "        'teresopolis': 'teres√≥polis',\n",
        "        'nova friburgo': 'nova friburgo',\n",
        "        'cabo frio': 'cabo frio',\n",
        "        'macae': 'maca√©',\n",
        "        'itatiaia': 'itatiaia',\n",
        "        'arraial do cabo': 'arraial do cabo',\n",
        "        'buzios': 'b√∫zios',\n",
        "        'saquarema': 'saquarema',\n",
        "        'marica': 'maric√°',\n",
        "        'itaborai': 'itabora√≠',\n",
        "        'sao goncalo': 's√£o gon√ßalo',\n",
        "        'niteroi': 'niter√≥i',\n",
        "        'duque de caxias': 'duque de caxias',\n",
        "        'nova iguacu': 'nova igua√ßu',\n",
        "        'sao joao de meriti': 's√£o jo√£o de meriti',\n",
        "        'belford roxo': 'belford roxo',\n",
        "        'queimados': 'queimados',\n",
        "        'itaguai': 'itagua√≠',\n",
        "        'seropedica': 'serop√©dica',\n",
        "        'paracambi': 'paracambi',\n",
        "        'japeri': 'japeri',\n",
        "        'mage': 'mag√©',\n",
        "        'guapimirim': 'guapimirim',\n",
        "        'cachoeiras de macacu': 'cachoeiras de macacu'\n",
        "    }\n",
        "\n",
        "    return corrections.get(city, city.title())\n",
        "\n",
        "# ÿØÿßŸÑÿ© ŸÑÿ™Ÿàÿ≠ŸäÿØ ÿ±ŸÖŸàÿ≤ ÿßŸÑŸàŸÑÿßŸäÿßÿ™\n",
        "def standardize_state(state):\n",
        "    if pd.isna(state):\n",
        "        return state\n",
        "\n",
        "    state = str(state).strip().upper()\n",
        "\n",
        "    # ŸÇÿßŸÖŸàÿ≥ ÿ±ŸÖŸàÿ≤ ÿßŸÑŸàŸÑÿßŸäÿßÿ™ ÿßŸÑÿ®ÿ±ÿßÿ≤ŸäŸÑŸäÿ© ÿßŸÑÿ±ÿ≥ŸÖŸäÿ©\n",
        "    state_codes = {\n",
        "        'AC': 'AC', 'AL': 'AL', 'AP': 'AP', 'AM': 'AM', 'BA': 'BA',\n",
        "        'CE': 'CE', 'DF': 'DF', 'ES': 'ES', 'GO': 'GO', 'MA': 'MA',\n",
        "        'MT': 'MT', 'MS': 'MS', 'MG': 'MG', 'PA': 'PA', 'PB': 'PB',\n",
        "        'PR': 'PR', 'PE': 'PE', 'PI': 'PI', 'RJ': 'RJ', 'RN': 'RN',\n",
        "        'RS': 'RS', 'RO': 'RO', 'RR': 'RR', 'SC': 'SC', 'SP': 'SP',\n",
        "        'SE': 'SE', 'TO': 'TO'\n",
        "    }\n",
        "\n",
        "    return state_codes.get(state, state)\n",
        "\n",
        "# ŸÇÿ±ÿßÿ°ÿ© ÿßŸÑÿ®ŸäÿßŸÜÿßÿ™\n",
        "df = pd.read_csv('olist_customers_dataset.csv')\n",
        "\n",
        "print(\"ÿßŸÑÿ®ŸäÿßŸÜÿßÿ™ ŸÇÿ®ŸÑ ÿßŸÑÿ™ŸÜÿ∏ŸäŸÅ:\")\n",
        "print(f\"ÿπÿØÿØ ÿßŸÑÿµŸÅŸàŸÅ: {len(df)}\")\n",
        "print(\"\\nÿ£ŸÖÿ´ŸÑÿ© ŸÖŸÜ ÿßŸÑÿ®ŸäÿßŸÜÿßÿ™ ÿßŸÑÿ£ÿµŸÑŸäÿ©:\")\n",
        "print(df[['customer_city', 'customer_state']].head(10))\n",
        "\n",
        "# ÿ™ÿ∑ÿ®ŸäŸÇ ÿßŸÑÿ™ŸÜÿ∏ŸäŸÅ ÿπŸÑŸâ ÿ£ÿ≥ŸÖÿßÿ° ÿßŸÑŸÖÿØŸÜ\n",
        "df['customer_city_cleaned'] = df['customer_city'].apply(clean_city_name)\n",
        "\n",
        "# ÿ™ÿ∑ÿ®ŸäŸÇ ÿßŸÑÿ™Ÿàÿ≠ŸäÿØ ÿπŸÑŸâ ÿ±ŸÖŸàÿ≤ ÿßŸÑŸàŸÑÿßŸäÿßÿ™\n",
        "df['customer_state_cleaned'] = df['customer_state'].apply(standardize_state)\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"ÿßŸÑÿ®ŸäÿßŸÜÿßÿ™ ÿ®ÿπÿØ ÿßŸÑÿ™ŸÜÿ∏ŸäŸÅ:\")\n",
        "print(f\"ÿπÿØÿØ ÿßŸÑÿµŸÅŸàŸÅ: {len(df)}\")\n",
        "print(\"\\nÿ£ŸÖÿ´ŸÑÿ© ŸÖŸÜ ÿßŸÑÿ®ŸäÿßŸÜÿßÿ™ ÿ®ÿπÿØ ÿßŸÑÿ™ŸÜÿ∏ŸäŸÅ:\")\n",
        "print(df[['customer_city', 'customer_city_cleaned', 'customer_state', 'customer_state_cleaned']].head(15))\n",
        "\n",
        "# ÿ•ÿ≠ÿµÿßÿ¶Ÿäÿßÿ™ ÿπŸÜ ÿßŸÑŸàŸÑÿßŸäÿßÿ™ ÿ®ÿπÿØ ÿßŸÑÿ™ŸÜÿ∏ŸäŸÅ\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"ÿ™Ÿàÿ≤Ÿäÿπ ÿßŸÑÿπŸÖŸÑÿßÿ° ÿ≠ÿ≥ÿ® ÿßŸÑŸàŸÑÿßŸäÿ© (ÿ®ÿπÿØ ÿßŸÑÿ™ŸÜÿ∏ŸäŸÅ):\")\n",
        "state_counts = df['customer_state_cleaned'].value_counts()\n",
        "print(state_counts)\n",
        "\n",
        "# ÿ≠ŸÅÿ∏ ÿßŸÑÿ®ŸäÿßŸÜÿßÿ™ ÿßŸÑŸÖŸÜÿ∏ŸÅÿ©\n",
        "df.to_csv('olist_customers_dataset_cleaned.csv', index=False)\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"‚úÖ ÿ™ŸÖ ÿ™ŸÜÿ∏ŸäŸÅ ÿßŸÑÿ®ŸäÿßŸÜÿßÿ™ Ÿàÿ≠ŸÅÿ∏Ÿáÿß ŸÅŸä: olist_customers_dataset_cleaned.csv\")\n",
        "print(f\"üìä ÿ•ÿ¨ŸÖÿßŸÑŸä ÿßŸÑÿπŸÖŸÑÿßÿ°: {len(df)}\")\n",
        "print(f\"üèôÔ∏è ÿπÿØÿØ ÿßŸÑŸÖÿØŸÜ ÿßŸÑŸÖŸÖŸäÿ≤ÿ©: {df['customer_city_cleaned'].nunique()}\")\n",
        "print(f\"üó∫Ô∏è ÿπÿØÿØ ÿßŸÑŸàŸÑÿßŸäÿßÿ™ ÿßŸÑŸÖŸÖŸäÿ≤ÿ©: {df['customer_state_cleaned'].nunique()}\")\n",
        "\n",
        "# ÿπÿ±ÿ∂ ÿ®ÿπÿ∂ ÿßŸÑÿ™ÿ∫ŸäŸäÿ±ÿßÿ™ ÿßŸÑÿ±ÿ¶Ÿäÿ≥Ÿäÿ©\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"ÿ£ŸáŸÖ ÿßŸÑÿ™ÿµÿ≠Ÿäÿ≠ÿßÿ™ ÿßŸÑÿ™Ÿä ÿ™ŸÖÿ™:\")\n",
        "changes = df[df['customer_city'] != df['customer_city_cleaned']][['customer_city', 'customer_city_cleaned']].head(10)\n",
        "if not changes.empty:\n",
        "    print(changes)\n",
        "else:\n",
        "    print(\"ŸÑÿß ÿ™Ÿàÿ¨ÿØ ÿ™ÿ∫ŸäŸäÿ±ÿßÿ™ ŸÉÿ®Ÿäÿ±ÿ© - ÿßŸÑÿ®ŸäÿßŸÜÿßÿ™ ŸÉÿßŸÜÿ™ ŸÜÿ∏ŸäŸÅÿ© ÿ®ÿßŸÑŸÅÿπŸÑ!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "McSo88rJPOlq",
        "outputId": "a009b089-9082-4898-c604-9ec6a8eb42c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ÿßŸÑÿ®ŸäÿßŸÜÿßÿ™ ŸÇÿ®ŸÑ ÿßŸÑÿ™ŸÜÿ∏ŸäŸÅ:\n",
            "ÿπÿØÿØ ÿßŸÑÿµŸÅŸàŸÅ: 99441\n",
            "\n",
            "ÿ£ŸÖÿ´ŸÑÿ© ŸÖŸÜ ÿßŸÑÿ®ŸäÿßŸÜÿßÿ™ ÿßŸÑÿ£ÿµŸÑŸäÿ©:\n",
            "           customer_city customer_state\n",
            "0                 franca             SP\n",
            "1  sao bernardo do campo             SP\n",
            "2              sao paulo             SP\n",
            "3        mogi das cruzes             SP\n",
            "4               campinas             SP\n",
            "5         jaragua do sul             SC\n",
            "6              sao paulo             SP\n",
            "7                timoteo             MG\n",
            "8               curitiba             PR\n",
            "9         belo horizonte             MG\n",
            "\n",
            "==================================================\n",
            "ÿßŸÑÿ®ŸäÿßŸÜÿßÿ™ ÿ®ÿπÿØ ÿßŸÑÿ™ŸÜÿ∏ŸäŸÅ:\n",
            "ÿπÿØÿØ ÿßŸÑÿµŸÅŸàŸÅ: 99441\n",
            "\n",
            "ÿ£ŸÖÿ´ŸÑÿ© ŸÖŸÜ ÿßŸÑÿ®ŸäÿßŸÜÿßÿ™ ÿ®ÿπÿØ ÿßŸÑÿ™ŸÜÿ∏ŸäŸÅ:\n",
            "            customer_city  customer_city_cleaned customer_state  \\\n",
            "0                  franca                 Franca             SP   \n",
            "1   sao bernardo do campo  s√£o bernardo do campo             SP   \n",
            "2               sao paulo              s√£o paulo             SP   \n",
            "3         mogi das cruzes        mogi das cruzes             SP   \n",
            "4                campinas               campinas             SP   \n",
            "5          jaragua do sul         jaragu√° do sul             SC   \n",
            "6               sao paulo              s√£o paulo             SP   \n",
            "7                 timoteo                tim√≥teo             MG   \n",
            "8                curitiba               curitiba             PR   \n",
            "9          belo horizonte         belo horizonte             MG   \n",
            "10          montes claros          Montes Claros             MG   \n",
            "11         rio de janeiro         rio de janeiro             RJ   \n",
            "12       lencois paulista       Lencois Paulista             SP   \n",
            "13              sao paulo              s√£o paulo             SP   \n",
            "14          caxias do sul          caxias do sul             RS   \n",
            "\n",
            "   customer_state_cleaned  \n",
            "0                      SP  \n",
            "1                      SP  \n",
            "2                      SP  \n",
            "3                      SP  \n",
            "4                      SP  \n",
            "5                      SC  \n",
            "6                      SP  \n",
            "7                      MG  \n",
            "8                      PR  \n",
            "9                      MG  \n",
            "10                     MG  \n",
            "11                     RJ  \n",
            "12                     SP  \n",
            "13                     SP  \n",
            "14                     RS  \n",
            "\n",
            "==================================================\n",
            "ÿ™Ÿàÿ≤Ÿäÿπ ÿßŸÑÿπŸÖŸÑÿßÿ° ÿ≠ÿ≥ÿ® ÿßŸÑŸàŸÑÿßŸäÿ© (ÿ®ÿπÿØ ÿßŸÑÿ™ŸÜÿ∏ŸäŸÅ):\n",
            "customer_state_cleaned\n",
            "SP    41746\n",
            "RJ    12852\n",
            "MG    11635\n",
            "RS     5466\n",
            "PR     5045\n",
            "SC     3637\n",
            "BA     3380\n",
            "DF     2140\n",
            "ES     2033\n",
            "GO     2020\n",
            "PE     1652\n",
            "CE     1336\n",
            "PA      975\n",
            "MT      907\n",
            "MA      747\n",
            "MS      715\n",
            "PB      536\n",
            "PI      495\n",
            "RN      485\n",
            "AL      413\n",
            "SE      350\n",
            "TO      280\n",
            "RO      253\n",
            "AM      148\n",
            "AC       81\n",
            "AP       68\n",
            "RR       46\n",
            "Name: count, dtype: int64\n",
            "\n",
            "==================================================\n",
            "‚úÖ ÿ™ŸÖ ÿ™ŸÜÿ∏ŸäŸÅ ÿßŸÑÿ®ŸäÿßŸÜÿßÿ™ Ÿàÿ≠ŸÅÿ∏Ÿáÿß ŸÅŸä: olist_customers_dataset_cleaned.csv\n",
            "üìä ÿ•ÿ¨ŸÖÿßŸÑŸä ÿßŸÑÿπŸÖŸÑÿßÿ°: 99441\n",
            "üèôÔ∏è ÿπÿØÿØ ÿßŸÑŸÖÿØŸÜ ÿßŸÑŸÖŸÖŸäÿ≤ÿ©: 4119\n",
            "üó∫Ô∏è ÿπÿØÿØ ÿßŸÑŸàŸÑÿßŸäÿßÿ™ ÿßŸÑŸÖŸÖŸäÿ≤ÿ©: 27\n",
            "\n",
            "==================================================\n",
            "ÿ£ŸáŸÖ ÿßŸÑÿ™ÿµÿ≠Ÿäÿ≠ÿßÿ™ ÿßŸÑÿ™Ÿä ÿ™ŸÖÿ™:\n",
            "            customer_city  customer_city_cleaned\n",
            "0                  franca                 Franca\n",
            "1   sao bernardo do campo  s√£o bernardo do campo\n",
            "2               sao paulo              s√£o paulo\n",
            "5          jaragua do sul         jaragu√° do sul\n",
            "6               sao paulo              s√£o paulo\n",
            "7                 timoteo                tim√≥teo\n",
            "10          montes claros          Montes Claros\n",
            "12       lencois paulista       Lencois Paulista\n",
            "13              sao paulo              s√£o paulo\n",
            "18              sao paulo              s√£o paulo\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. ÿ™ÿ≠ŸàŸäŸÑ ÿ¨ŸÖŸäÿπ ÿßŸÑÿ£ÿπŸÖÿØÿ© ÿßŸÑÿ≤ŸÖŸÜŸäÿ© ÿ•ŸÑŸâ datetime\n",
        "date_cols = [\n",
        "    'order_purchase_timestamp',\n",
        "    'order_approved_at',\n",
        "    'order_delivered_carrier_date',\n",
        "    'order_delivered_customer_date',\n",
        "    'order_estimated_delivery_date'\n",
        "]\n",
        "\n",
        "for col in date_cols:\n",
        "    # ÿßÿ≥ÿ™ÿÆÿØÿßŸÖ errors='coerce' ŸÑŸàÿ∂ÿπ NaT (Null) ÿ•ÿ∞ÿß ŸÉÿßŸÜ ÿßŸÑÿ™ÿ≠ŸàŸäŸÑ ŸÖÿ≥ÿ™ÿ≠ŸäŸÑÿßŸã\n",
        "    orders[col] = pd.to_datetime(orders[col], errors='coerce')\n",
        "\n",
        "# 2. ŸÖÿπÿßŸÑÿ¨ÿ© ÿßŸÑŸÄ Nulls ÿßŸÑÿ£ÿ≥ÿßÿ≥Ÿäÿ©:\n",
        "# ÿßŸÑŸÇŸäŸÖÿ© ÿßŸÑŸÖŸÅŸÇŸàÿØÿ© ŸÅŸä ÿ™ÿßÿ±ŸäÿÆ ÿßŸÑÿ¥ÿ±ÿßÿ° (order_purchase_timestamp) Ÿäÿ¨ÿ® ÿ≠ÿ∞ŸÅŸáÿß ŸÑÿ£ŸÜŸá ŸÑÿß ŸäŸÖŸÉŸÜ ÿßÿ≥ÿ™ÿ±ÿ¨ÿßÿπŸáÿß ŸÖŸÜÿ∑ŸÇŸäÿßŸã.\n",
        "orders.dropna(subset=['order_purchase_timestamp'], inplace=True)"
      ],
      "metadata": {
        "id": "nXTzZpg_Ya2C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# The 'orders' DataFrame has already been loaded and cleaned in previous steps.\n",
        "# This cell's purpose is to save the *cleaned* orders DataFrame to a CSV.\n",
        "\n",
        "# Ensure datetime columns are correctly typed before saving, if they aren't already.\n",
        "# This step is largely redundant if previous cleaning steps were successful,\n",
        "# but it's a good practice for final output.\n",
        "date_cols_to_check = [\n",
        "    'order_purchase_timestamp',\n",
        "    'order_approved_at',\n",
        "    'order_delivered_carrier_date',\n",
        "    'order_delivered_customer_date',\n",
        "    'order_estimated_delivery_date'\n",
        "]\n",
        "for col in date_cols_to_check:\n",
        "    if col in orders.columns:\n",
        "        orders[col] = pd.to_datetime(orders[col], errors='coerce')\n",
        "\n",
        "# We will use the globally available and already cleaned 'orders' DataFrame.\n",
        "# If you specifically wanted a DataFrame containing *only* delivered orders,\n",
        "# you would create it here from the global 'orders' DataFrame.\n",
        "# For now, we save the full cleaned 'orders' DataFrame.\n",
        "df_orders_cleaned_final = orders.copy()\n",
        "\n",
        "# Optional: If you only want 'delivered' orders saved, uncomment the line below:\n",
        "# df_orders_cleaned_final = orders[orders['order_status'] == 'delivered'].copy()\n",
        "\n",
        "# Saving the cleaned DataFrame to a new CSV file\n",
        "df_orders_cleaned_final.to_csv('olist_orders_CLEANED.csv', index=False)"
      ],
      "metadata": {
        "id": "CrtDmWw5ZD5F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. ÿ™ÿ≠ŸÖŸäŸÑ ÿßŸÑŸÖŸÑŸÅ\n",
        "df_products = pd.read_csv('olist_products_dataset.csv')\n",
        "\n",
        "# 2. ÿ™ÿπÿ®ÿ¶ÿ© ÿßŸÑŸÇŸäŸÖ ÿßŸÑŸÖŸÅŸÇŸàÿØÿ© ŸÅŸä ŸÅÿ¶ÿ© ÿßŸÑŸÖŸÜÿ™ÿ¨\n",
        "df_products['product_category_name'].fillna('no_category', inplace=True)\n",
        "\n",
        "# 3. ÿ≠ŸÅÿ∏ ÿßŸÑŸÖŸÑŸÅ ÿßŸÑŸÜÿ∏ŸäŸÅ\n",
        "df_products.to_csv('olist_products_CLEANED.csv', index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K5swQJ2SkWiE",
        "outputId": "d6d09532-1ef6-4918-9410-3df21f682f91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4073037026.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df_products['product_category_name'].fillna('no_category', inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ÿ™ŸÜÿ∏ŸäŸÅ ÿßŸÑŸÖÿØŸÅŸàÿπÿßÿ™\n",
        "df_payments = pd.read_csv('olist_order_payments_dataset.csv')\n",
        "df_payments.dropna(subset=['payment_type', 'payment_value'], inplace=True)\n",
        "df_payments.to_csv('olist_order_payments_CLEANED.csv', index=False)\n",
        "\n",
        "# ÿ™ŸÜÿ∏ŸäŸÅ ÿßŸÑŸÖŸàŸÇÿπ ÿßŸÑÿ¨ÿ∫ÿ±ÿßŸÅŸä\n",
        "df_geolocation = pd.read_csv('olist_geolocation_dataset.csv')\n",
        "df_geolocation.dropna(subset=['geolocation_city', 'geolocation_state'], inplace=True)\n",
        "df_geolocation.to_csv('olist_geolocation_CLEANED.csv', index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "svoQU8o1kkDX",
        "outputId": "9100eb7f-4db4-4bed-9563-24b6b2423e59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'olist_order_payments_dataset.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2537733255.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# ÿ™ŸÜÿ∏ŸäŸÅ ÿßŸÑŸÖÿØŸÅŸàÿπÿßÿ™\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_payments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'olist_order_payments_dataset.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf_payments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'payment_type'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'payment_value'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf_payments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'olist_order_payments_CLEANED.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'olist_order_payments_dataset.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import sqlite3\n",
        "import glob\n",
        "import os\n",
        "\n",
        "# 1. ÿ™ÿ≠ÿØŸäÿØ ÿßÿ≥ŸÖ ŸÇÿßÿπÿØÿ© ÿßŸÑÿ®ŸäÿßŸÜÿßÿ™\n",
        "db_name = 'olist_analysiiis_db.sqlite'\n",
        "\n",
        "# 2. ÿ•ŸÜÿ¥ÿßÿ° ÿßÿ™ÿµÿßŸÑ ÿ®ŸÇÿßÿπÿØÿ© ÿßŸÑÿ®ŸäÿßŸÜÿßÿ™\n",
        "# ÿ•ÿ∞ÿß ŸÑŸÖ ŸäŸÉŸÜ ÿßŸÑŸÖŸÑŸÅ ŸÖŸàÿ¨ŸàÿØÿßŸãÿå ÿ≥Ÿäÿ™ŸÖ ÿ•ŸÜÿ¥ÿßÿ§Ÿá ÿ™ŸÑŸÇÿßÿ¶ŸäÿßŸã\n",
        "conn = sqlite3.connect(db_name)\n",
        "\n",
        "# 3. ŸÇÿßÿ¶ŸÖÿ© ÿ®ÿ¨ŸÖŸäÿπ ŸÖŸÑŸÅÿßÿ™ CSV ÿßŸÑŸÜÿ∏ŸäŸÅÿ©\n",
        "csv_files = glob.glob('olist_*_dataset.csv')\n",
        "csv_files.append('product_category_name_translation.csv')\n",
        "\n",
        "print(f\"ÿ¨ÿßÿ±Ÿä ÿ™ÿ≠ŸÖŸäŸÑ {len(csv_files)} ÿ¨ÿØŸàŸÑ ÿ•ŸÑŸâ ŸÇÿßÿπÿØÿ© ÿßŸÑÿ®ŸäÿßŸÜÿßÿ™ {db_name}...\")\n",
        "\n",
        "for file in csv_files:\n",
        "    try:\n",
        "        # ŸÇÿ±ÿßÿ°ÿ© ÿßŸÑŸÖŸÑŸÅ (ŸäŸÅÿ™ÿ±ÿ∂ ÿ£ŸÜŸÉ ÿßÿ≥ÿ™ÿÆÿØŸÖÿ™ ÿßŸÑŸÖŸÑŸÅÿßÿ™ ÿßŸÑŸÜÿ∏ŸäŸÅÿ© ÿ£Ÿà ÿπÿØŸÑÿ™Ÿáÿß)\n",
        "        df = pd.read_csv(file)\n",
        "\n",
        "        # ÿßÿ≥ÿ™ÿÆÿ±ÿßÿ¨ ÿßÿ≥ŸÖ ÿßŸÑÿ¨ÿØŸàŸÑ ŸÖŸÜ ÿßÿ≥ŸÖ ÿßŸÑŸÖŸÑŸÅ (ŸÖÿ´ŸÑÿßŸã: olist_customers_dataset.csv -> olist_customers)\n",
        "        # ÿ•ÿ≤ÿßŸÑÿ© '.csv'\n",
        "        table_name = file.replace('.csv', '')\n",
        "\n",
        "        # ÿ®ÿπÿ∂ ÿ£ÿ≥ŸÖÿßÿ° ÿßŸÑÿ¨ÿØÿßŸàŸÑ ÿ∑ŸàŸäŸÑÿ©ÿå ŸäŸÖŸÉŸÜŸÉ ÿßÿÆÿ™ÿµÿßÿ±Ÿáÿß ŸÑÿ™ÿ≥ŸáŸäŸÑ ÿßŸÑÿ™ÿπÿßŸÖŸÑ ŸÅŸä SQL\n",
        "        if 'olist_orders_dataset' in table_name:\n",
        "            table_name = 'orders'\n",
        "        elif 'olist_order_items_dataset' in table_name:\n",
        "            table_name = 'order_items'\n",
        "        elif 'olist_order_payments_dataset' in table_name:\n",
        "            table_name = 'payments'\n",
        "        elif 'olist_products_dataset' in table_name:\n",
        "            table_name = 'products'\n",
        "\n",
        "        # 4. ÿ™ÿ≠ŸÖŸäŸÑ ÿßŸÑÿ®ŸäÿßŸÜÿßÿ™ ÿ•ŸÑŸâ ÿ¨ÿØŸàŸÑ SQL\n",
        "        # if_exists='replace': ŸäÿπŸÜŸä ÿßÿ≥ÿ™ÿ®ÿØÿßŸÑ ÿßŸÑÿ¨ÿØŸàŸÑ ÿ•ÿ∞ÿß ŸÉÿßŸÜ ŸÖŸàÿ¨ŸàÿØÿßŸã\n",
        "        df.to_sql(table_name, conn, if_exists='replace', index=False)\n",
        "\n",
        "        print(f\"‚úÖ ÿ™ŸÖ ÿ™ÿ≠ŸÖŸäŸÑ ÿßŸÑÿ¨ÿØŸàŸÑ: {table_name}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå ÿÆÿ∑ÿ£ ŸÅŸä ÿ™ÿ≠ŸÖŸäŸÑ ÿßŸÑŸÖŸÑŸÅ {file}: {e}\")\n",
        "\n",
        "# 5. ÿ•ÿ∫ŸÑÿßŸÇ ÿßŸÑÿßÿ™ÿµÿßŸÑ\n",
        "conn.close()\n",
        "\n",
        "print(\"\\nÿ™ŸÖÿ™ ÿπŸÖŸÑŸäÿ© ÿ™ÿ≠ŸÖŸäŸÑ ÿßŸÑÿ®ŸäÿßŸÜÿßÿ™ ÿ®ŸÜÿ¨ÿßÿ≠. ŸÇÿßÿπÿØÿ© ÿ®ŸäÿßŸÜÿßÿ™ŸÉ ÿ¨ÿßŸáÿ≤ÿ©.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mO2YrflKyvub",
        "outputId": "834ed7d8-8305-4e81-deb5-a87d5b7291cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ÿ¨ÿßÿ±Ÿä ÿ™ÿ≠ŸÖŸäŸÑ 1 ÿ¨ÿØŸàŸÑ ÿ•ŸÑŸâ ŸÇÿßÿπÿØÿ© ÿßŸÑÿ®ŸäÿßŸÜÿßÿ™ olist_analysiiis_db.sqlite...\n",
            "‚ùå ÿÆÿ∑ÿ£ ŸÅŸä ÿ™ÿ≠ŸÖŸäŸÑ ÿßŸÑŸÖŸÑŸÅ product_category_name_translation.csv: [Errno 2] No such file or directory: 'product_category_name_translation.csv'\n",
            "\n",
            "ÿ™ŸÖÿ™ ÿπŸÖŸÑŸäÿ© ÿ™ÿ≠ŸÖŸäŸÑ ÿßŸÑÿ®ŸäÿßŸÜÿßÿ™ ÿ®ŸÜÿ¨ÿßÿ≠. ŸÇÿßÿπÿØÿ© ÿ®ŸäÿßŸÜÿßÿ™ŸÉ ÿ¨ÿßŸáÿ≤ÿ©.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "nb1HLaQRy4QB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}